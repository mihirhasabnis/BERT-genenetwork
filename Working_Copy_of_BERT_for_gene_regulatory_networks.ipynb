{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihirhasabnis/BERT-genenetwork/blob/main/Working_Copy_of_BERT_for_gene_regulatory_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-8kZmr4ItGUj"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import re\n",
        "import random\n",
        "from random import *\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w6YMNvc8tbA9"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/rand_walk_1.txt\") as f:\n",
        "  random_walk_text = f.read().split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CFpfs1Dxttpn"
      },
      "outputs": [],
      "source": [
        "sentences = []\n",
        "for i in range(len(random_walk_text)):\n",
        "  sentences.append(re.sub(\"[.,!?\\\\-]\", '',str(random_walk_text[i][1:-2])))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pqjs1uMCP9dv"
      },
      "outputs": [],
      "source": [
        "gene_dic = defaultdict(int)\n",
        "for i in range(len(sentences)):\n",
        "  for j in range(len(sentences[i].split(\" \"))):\n",
        "    gene_dic[sentences[i].split(\" \")[j]] = gene_dic.get(sentences[i].split(\" \")[j],0)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QtKaeTAPP9aW"
      },
      "outputs": [],
      "source": [
        "word_dict = defaultdict(int)\n",
        "word_dict['[PAD]'] = 0\n",
        "word_dict['[CLS]'] = 1\n",
        "word_dict['[SEP]'] = 2\n",
        "word_dict['[MASK]'] = 3\n",
        "for idx,gene in enumerate(gene_dic):\n",
        "  word_dict[gene] = idx+4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTg9GtjLUCaa",
        "outputId": "d1d47e7d-9930-4932-9219-1ee95e8e442b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[PAD]', 0), ('[CLS]', 1), ('[SEP]', 2), ('[MASK]', 3), (\"'A1BG'\", 4), (\"'GAB3'\", 5), (\"'CSF1'\", 6), (\"'CXCL1'\", 7), (\"'IL18\", 8), (\"'A1CF'\", 9)]\n"
          ]
        }
      ],
      "source": [
        "print(list(word_dict.items())[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qmFBTQ4eP9UY"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(word_dict)\n",
        "#dic mapping index to word/gene\n",
        "number_dict = {i: w for i, w in enumerate(word_dict)}\n",
        "word_list = list(set(\" \".join(sentences).split()))\n",
        "#token list  = [[tokens_s1], [tokens_s2],....]\n",
        "token_list = list()\n",
        "for sentence in sentences:\n",
        "    arr = [word_dict[s] for s in sentence.split()]\n",
        "    token_list.append(arr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Sswti5--0dFZ"
      },
      "outputs": [],
      "source": [
        "class RandomWalkDataset(Dataset):\n",
        "  def __init__(self,sentences,token_list,word_dict,number_dict,vocab_size,maxlen,max_pred):\n",
        "    self.sentences= sentences\n",
        "    self.token_list = token_list\n",
        "    self.word_dict = word_dict\n",
        "    self.number_dict = number_dict\n",
        "    self.vocab_size = vocab_size\n",
        "    self.maxlen = maxlen\n",
        "    self.max_pred = max_pred\n",
        "  def __len__(self):\n",
        "    return len(self.sentences)\n",
        "  def __getitem__(self,idx):\n",
        "    #get random sentence pair\n",
        "    tokens_a_index =  randrange(len(self.sentences)) #randomly pick a sentence for A\n",
        "    tokens_b_index= randrange(len(self.sentences)) #randomly pick a sentence for B\n",
        "    #get the token lists corr to A and B\n",
        "    tokens_a =  token_list[tokens_a_index] #get list of tokens for corr A sentence\n",
        "    tokens_b= token_list[tokens_b_index] #get list of tokens for corr B sentence\n",
        "    input_ids = [self.word_dict['[CLS]']] + tokens_a + [self.word_dict['[SEP]']] + tokens_b + [self.word_dict['[SEP]']]\n",
        "    #input ids and segment ids containining tokens pertaining to each sentence, 0 for A and 1 for B\n",
        "    segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
        "    n_pred =  min(self.max_pred, max(1, int(round(len(input_ids) * 0.15)))) # 15 % of tokens in one sentence, will always be 2 in this case\n",
        "\n",
        "    cand_masked_pos = [i for i, token in enumerate(input_ids)\n",
        "                      if token != self.word_dict['[CLS]'] and token != self.word_dict['[SEP]']]  #candidates for masking, cant be CLS or SEP\n",
        "    shuffle(cand_masked_pos)    #shuffles the list in-place\n",
        "    masked_tokens, masked_pos, output_labels = [], [], []\n",
        "    for pos in cand_masked_pos[:n_pred]:\n",
        "      masked_pos.append(pos) #stores pos within input ids of token to be masked\n",
        "      masked_tokens.append(input_ids[pos]) #stores the actual token which is masked...used for comparison/loss\n",
        "      if random() < 0.8:  # 80% of the time we create a mask at pos\n",
        "        #output_labels.append(input_ids[pos])\n",
        "        input_ids[pos] = self.word_dict['[MASK]'] # make mask\n",
        "      elif random() < 0.1:  # 10%\n",
        "        index = randint(0, self.vocab_size - 1) # random index in vocabulary\n",
        "        #output_labels.append(input_ids[pos])\n",
        "        input_ids[pos] = self.word_dict[self.number_dict[index]] # we intentionally replace token at pos with a wrong token\n",
        "      else:\n",
        "        pass\n",
        "    # Zero Paddings, add padding where necessary to have sentences of uniform length\n",
        "    n_pad = self.maxlen - len(input_ids)\n",
        "    input_ids.extend([0] * n_pad)\n",
        "    segment_ids.extend([0] * n_pad)\n",
        "    # Zero Padding (100% - 15%) tokens\n",
        "    if self.max_pred > n_pred:\n",
        "      n_pad = self.max_pred - n_pred\n",
        "      masked_tokens.extend([0] * n_pad)\n",
        "      masked_pos.extend([0] * n_pad)\n",
        "    if tokens_a_index + 1 == tokens_b_index: #if B comes directly after A, nsp = True\n",
        "      is_next_label = 1 # IsNext\n",
        "    elif tokens_a_index + 1 != tokens_b_index:\n",
        "      is_next_label = 0 # NotNext\n",
        "    output = {\"bert_input\": input_ids,\n",
        "              \"bert_label\": masked_tokens,\n",
        "              \"segment_label\": segment_ids,\n",
        "              \"is_next\": is_next_label,\n",
        "              \"masked_pos\":masked_pos}\n",
        "\n",
        "    return {key: torch.tensor(value) for key, value in output.items()}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b20ZnOnKAZm5",
        "outputId": "0017d74c-73e9-4f59-98d8-65739407484c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\")\n",
        "train_data = RandomWalkDataset(sentences, token_list,word_dict,number_dict,vocab_size,maxlen=15,max_pred=5)\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "batch = next(iter(train_loader))\n",
        "input_ids = batch['bert_input']\n",
        "segment_ids = batch['segment_label']\n",
        "input_ids = batch['bert_input'].to(device)\n",
        "segment_ids = batch['segment_label'].to(device)\n",
        "labels = batch['bert_label'].to(device)\n",
        "isNext = batch['is_next'].to(device)\n",
        "masked_pos = batch['masked_pos'].to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Q03SGkfIu_Kd"
      },
      "outputs": [],
      "source": [
        "maxlen = 15 # maximum length\n",
        "batch_size = 32\n",
        "max_pred = 5  # max tokens of prediction\n",
        "n_layers = 6 # number of Encoder of Encoder Layer\n",
        "n_heads = 2 # number of heads in Multi-Head Attention\n",
        "d_model = 32 # Embedding Size\n",
        "d_ff = 32 * 4  # 4*d_model, FeedForward dimension\n",
        "d_k = d_v = 16  # dimension of K(=Q), V, tpyically d_model//n_heads\n",
        "n_segments = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TtyOOmRntu8w"
      },
      "outputs": [],
      "source": [
        "\n",
        "# def make_batch():\n",
        "#     batch = []\n",
        "#     positive = 0\n",
        "#     negative = 0\n",
        "#     while positive != batch_size/2 or negative != batch_size/2:\n",
        "#         tokens_a_index =  randrange(len(sentences)) #randomly pick a sentence for A\n",
        "#         tokens_b_index= randrange(len(sentences)) #randomly pick a sentence for B\n",
        "#         tokens_a =  token_list[tokens_a_index] #get list of tokens for corr A sentence\n",
        "#         tokens_b= token_list[tokens_b_index] #get list of tokens for corr B sentence\n",
        "\n",
        "#         input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']] #list containining tokens pertaining to each sentence\n",
        "\n",
        "#         segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1) #init to list of zeros, size corr to length of input_ids\n",
        "\n",
        "#         #MASK LM\n",
        "#         n_pred =  min(max_pred, max(1, int(round(len(input_ids) * 0.15)))) # 15 % of tokens in one sentence, will always be 2 in this case\n",
        "\n",
        "#         cand_maked_pos = [i for i, token in enumerate(input_ids)\n",
        "#                           if token != word_dict['[CLS]'] and token != word_dict['[SEP]']]  #candidates for masking, cant be CLS or SEP\n",
        "#         shuffle(cand_maked_pos)    #shuffles the list in-place\n",
        "#         masked_tokens, masked_pos = [], []\n",
        "#         for pos in cand_maked_pos[:n_pred]:\n",
        "#             masked_pos.append(pos)\n",
        "#             masked_tokens.append(input_ids[pos])\n",
        "#             if random() < 0.8:  # 80% of the time we create a mask at pos\n",
        "#                 input_ids[pos] = word_dict['[MASK]'] # make mask\n",
        "#             elif random() < 0.2:  # 10%\n",
        "#                 index = randint(0, vocab_size - 1) # random index in vocabulary\n",
        "#                 input_ids[pos] = word_dict[number_dict[index]] # we intentionally replace token at pos with a wrong token\n",
        "\n",
        "#         # Zero Paddings, add padding where necessary to have sentences of uniform length\n",
        "#         n_pad = maxlen - len(input_ids)\n",
        "#         input_ids.extend([0] * n_pad)\n",
        "#         segment_ids.extend([0] * n_pad)\n",
        "\n",
        "#         # Zero Padding (100% - 15%) tokens\n",
        "#         if max_pred > n_pred:\n",
        "#             n_pad = max_pred - n_pred\n",
        "#             masked_tokens.extend([0] * n_pad)\n",
        "#             masked_pos.extend([0] * n_pad)\n",
        "\n",
        "#         # if positive < batch_size/2:\n",
        "#         #   batch.append([input_ids, segment_ids, masked_tokens, masked_pos])\n",
        "#         #   positive += 1\n",
        "#         if tokens_a_index + 1 == tokens_b_index and positive < batch_size/2: #if B comes directly after A, nsp = True\n",
        "#             batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True]) # IsNext\n",
        "#             positive += 1\n",
        "#         elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2:\n",
        "#             batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False]) # NotNext\n",
        "#             negative += 1\n",
        "#     return batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "s1PGksqBNuZM"
      },
      "outputs": [],
      "source": [
        "def get_attn_pad_mask(seq_q, seq_k):  ##masking for PAD tokens ie 0 tokens\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    # eq(zero) is PAD token\n",
        "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
        "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k, just creates a new view of the tensor with singleton dim expanded to specified size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lgJwW4OaiXE2"
      },
      "outputs": [],
      "source": [
        "def gelu(x): #gaussian activiation function, known to improve performance in transformer models\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Qnay0LTDjE4S"
      },
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.tok_embed = nn.Embedding(vocab_size, d_model,device = device)  # token embedding\n",
        "        self.pos_embed = nn.Embedding(maxlen, d_model,device = device)  # position embedding\n",
        "        self.seg_embed = nn.Embedding(n_segments, d_model,device = device)  # segment(token type) embedding\n",
        "        self.norm = nn.LayerNorm(d_model,device = device)\n",
        "\n",
        "    def forward(self, x, seg):\n",
        "        seq_len = x.size(1)\n",
        "        pos = torch.arange(seq_len, dtype=torch.long).to(device)\n",
        "        pos = pos.unsqueeze(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n",
        "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
        "        return self.norm(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rHjj-1wXjsdI"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
        "        attn = nn.Softmax(dim=-1)(scores)\n",
        "        context = torch.matmul(attn, V)\n",
        "        return scores,context, attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "8X2rbGNMzl7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f5ab5b-2d3a-4e6f-f8c5-36985fe5ffbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 cuda:0 cuda:0\n",
            "Masks tensor([False, False, False, False, False, False, False, False, False, False,\n",
            "        False, False, False,  True,  True], device='cuda:0')\n",
            "Scores:  tensor([ 8.0000e+00,  3.1788e+00,  3.1824e+00,  4.0196e+00,  3.5082e+00,\n",
            "         4.3209e+00,  3.3790e+00,  6.6363e-01,  8.4407e-01, -2.8773e-01,\n",
            "        -7.4362e-01,  2.9213e-01, -2.1224e-01, -1.0000e+09, -1.0000e+09],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>) \n",
            "\n",
            "Attention M:  tensor([9.2278e-01, 7.4355e-03, 7.4620e-03, 1.7237e-02, 1.0336e-02, 2.3298e-02,\n",
            "        9.0834e-03, 6.0113e-04, 7.2000e-04, 2.3216e-04, 1.4716e-04, 4.1459e-04,\n",
            "        2.5037e-04, 0.0000e+00, 0.0000e+00], device='cuda:0',\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# emb = Embedding()\n",
        "\n",
        "# embeds = emb(input_ids, segment_ids)\n",
        "\n",
        "# attenM = get_attn_pad_mask(input_ids, input_ids)\n",
        "\n",
        "# SDPA= ScaledDotProductAttention()(embeds, embeds, embeds, attenM)\n",
        "\n",
        "# S,C, A = SDPA\n",
        "# print('Masks',attenM[0][0])\n",
        "# # print()\n",
        "# print('Scores: ', S[0][0],'\\n\\nAttention M: ', A[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "hUX_eM_E1B8p"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.W_Q = nn.Linear(d_model, d_k * n_heads,device= device)\n",
        "        self.W_K = nn.Linear(d_model, d_k * n_heads,device=device)\n",
        "        self.W_V = nn.Linear(d_model, d_v * n_heads,device=device)\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
        "        residual, batch_size = Q, Q.size(0)\n",
        "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
        "        k_s = self.W_K(K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
        "        v_s = self.W_V(V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
        "\n",
        "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        scores,context, attn = ScaledDotProductAttention()(q_s, k_s, v_s, attn_mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_heads * d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
        "        output = nn.Linear(n_heads * d_v, d_model,device=device)(context)\n",
        "        return nn.LayerNorm(d_model,device=device)(output + residual), attn # output: [batch_size x len_q x d_model]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Zs_xOAZy3pay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23bf4a59-cb77-4034-ad1a-ab0904ef68f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# emb = Embedding()\n",
        "# embeds = emb(input_ids, segment_ids)\n",
        "\n",
        "# attenM = get_attn_pad_mask(input_ids, input_ids)\n",
        "# MHA = MultiHeadAttention()(embeds, embeds, embeds, attenM)\n",
        "\n",
        "# Output, A = MHA\n",
        "\n",
        "# A[0][0].device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "_GQFL_Va4N4Y"
      },
      "outputs": [],
      "source": [
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff,device=device)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model,device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
        "        return self.fc2(gelu(self.fc1(x)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "RgmfjTqw4Qnw"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.enc_self_attn = MultiHeadAttention()\n",
        "        self.pos_ffn = PoswiseFeedForwardNet()\n",
        "\n",
        "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
        "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
        "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
        "        return enc_outputs, attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "OZ0TJ84W4SZw"
      },
      "outputs": [],
      "source": [
        "class BERT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT, self).__init__()\n",
        "        self.embedding = Embedding()\n",
        "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
        "        self.fc = nn.Linear(d_model, d_model,device=device)\n",
        "        self.activ1 = nn.Tanh()\n",
        "        self.linear = nn.Linear(d_model, d_model,device=device)\n",
        "        self.activ2 = gelu\n",
        "        self.norm = nn.LayerNorm(d_model,device=device)\n",
        "        self.classifier = nn.Linear(d_model, 2,device=device)\n",
        "        # decoder is shared with embedding layer\n",
        "        embed_weight = self.embedding.tok_embed.weight\n",
        "        n_vocab, n_dim = embed_weight.size()\n",
        "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False,device=device)\n",
        "        self.decoder.weight = embed_weight\n",
        "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
        "\n",
        "    def forward(self, input_ids, segment_ids, masked_pos):\n",
        "        output = self.embedding(input_ids, segment_ids)\n",
        "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)\n",
        "        for layer in self.layers:\n",
        "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
        "        # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
        "        # it will be decided by first token(CLS)\n",
        "        h_pooled = self.activ1(self.fc(output[:, 0])) # [batch_size, d_model]\n",
        "        logits_clsf = self.classifier(h_pooled) # [batch_size, 2]\n",
        "\n",
        "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) # [batch_size, max_pred, d_model]\n",
        "        # get masked position from final output of transformer.\n",
        "        h_masked = torch.gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
        "        h_masked = self.norm(self.activ2(self.linear(h_masked)))\n",
        "        logits_lm = self.decoder(h_masked) + self.decoder_bias # [batch_size, max_pred, n_vocab]\n",
        "\n",
        "        return logits_lm, logits_clsf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsRMMQZw3f0X",
        "outputId": "b5cdfac0-5ca6-4544-e289-5dabb214ecc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERT(\n",
              "  (embedding): Embedding(\n",
              "    (tok_embed): Embedding(21552, 32)\n",
              "    (pos_embed): Embedding(15, 32)\n",
              "    (seg_embed): Embedding(2, 32)\n",
              "    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (layers): ModuleList(\n",
              "    (0-5): 6 x EncoderLayer(\n",
              "      (enc_self_attn): MultiHeadAttention(\n",
              "        (W_Q): Linear(in_features=32, out_features=32, bias=True)\n",
              "        (W_K): Linear(in_features=32, out_features=32, bias=True)\n",
              "        (W_V): Linear(in_features=32, out_features=32, bias=True)\n",
              "      )\n",
              "      (pos_ffn): PoswiseFeedForwardNet(\n",
              "        (fc1): Linear(in_features=32, out_features=128, bias=True)\n",
              "        (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (activ1): Tanh()\n",
              "  (linear): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
              "  (classifier): Linear(in_features=32, out_features=2, bias=True)\n",
              "  (decoder): Linear(in_features=32, out_features=21552, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "model = BERT()\n",
        "model.train()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "cOrNd-1J67ik"
      },
      "outputs": [],
      "source": [
        "train_data = RandomWalkDataset(sentences, token_list,word_dict,number_dict,vocab_size,maxlen=15,max_pred=5)\n",
        "train_loader = DataLoader(train_data, batch_size=6) #shuffle=True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UAG3SEP4UbU",
        "outputId": "877a2200-dab3-46e0-a52e-360cd82bf470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch0: 100%|██████████| 2462/2462 [01:08<00:00, 35.95it/s, loss=4.02]\n",
            "epoch1: 100%|██████████| 2462/2462 [01:07<00:00, 36.21it/s, loss=3.59]\n",
            "epoch2: 100%|██████████| 2462/2462 [01:10<00:00, 35.16it/s, loss=3.53]\n",
            "epoch3: 100%|██████████| 2462/2462 [01:07<00:00, 36.24it/s, loss=3.89]\n",
            "epoch4: 100%|██████████| 2462/2462 [01:08<00:00, 36.05it/s, loss=3.77]\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters(), lr=0.0001)\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    loop = tqdm(train_loader)\n",
        "    for batch in loop:\n",
        "      optimizer.zero_grad()\n",
        "      input_ids = batch['bert_input'].to(device)\n",
        "      segment_ids = batch['segment_label'].to(device)\n",
        "      labels = batch['bert_label'].to(device)\n",
        "      isNext = batch['is_next'].to(device)\n",
        "      masked_pos = batch['masked_pos'].to(device)\n",
        "      logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
        "      loss_lm = criterion(logits_lm.transpose(1, 2), labels) # for masked LM\n",
        "      loss_lm = (loss_lm.float()).mean()\n",
        "      loss_clsf = criterion(logits_clsf, isNext) # for sentence classification\n",
        "      loss = loss_lm + loss_clsf\n",
        "      loop.set_description(f\"epoch{epoch}\")\n",
        "      loop.set_postfix(loss = loss.item())\n",
        "      # if (epoch + 1) % 10 == 0:\n",
        "      #   print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xmfz1hbx4B9R"
      },
      "outputs": [],
      "source": [
        "sample_batch = next(iter(train_loader))\n",
        "sample_point = train_data[0]\n",
        "sample_point\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do2cKU9I7gwL"
      },
      "outputs": [],
      "source": [
        "input_ids = sample_point['bert_input']\n",
        "segment_ids = sample_point['segment_label']\n",
        "masked_pos = sample_point['masked_pos']\n",
        "masked_tokens = sample_point['bert_label']\n",
        "input_ids,segment_ids,masked_pos,masked_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaI-XKhL7jBJ"
      },
      "outputs": [],
      "source": [
        "a = input_ids.unsqueeze(0)\n",
        "b = segment_ids.unsqueeze(0)\n",
        "c = masked_pos.unsqueeze(0)\n",
        "d = masked_tokens.unsqueeze(0)\n",
        "x,y = model(a,b,c)\n",
        "x = x.data.max(2)[1][0].data.numpy()\n",
        "print('masked tokens list:',[pos.item() for pos in d[0] if pos.item() != 0])\n",
        "print('predict masked tokens list : ',[pos for pos in x if pos != 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENmH8CJ-dGVn"
      },
      "outputs": [],
      "source": [
        "x,y = model(a,b,c)\n",
        "print(x.size())\n",
        "print(x.data)\n",
        "print(x.data.max(2)[1][0].data.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD3K8T6B4YJp"
      },
      "outputs": [],
      "source": [
        "# #Predict mask tokens ans isNext\n",
        "# input_ids, segment_ids, masked_tokens, masked_pos, isNext = map(torch.LongTensor, zip(batch[3]))\n",
        "# #print(text)\n",
        "# print([number_dict[w.item()] for w in input_ids[0] if number_dict[w.item()] != '[PAD]'])\n",
        "\n",
        "# logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
        "# logits_lm = logits_lm.data.max(2)[1][0].data.numpy()\n",
        " #print('masked tokens list : ',[pos.item() for pos in masked_tokens[0] if pos.item() != 0])\n",
        "# print('predict masked tokens list : ',[pos for pos in logits_lm if pos != 0])\n",
        "\n",
        "# logits_clsf = logits_clsf.data.max(1)[1].data.numpy()[0]\n",
        "# # print('isNext : ', True if isNext else False)\n",
        "# # print('predict isNext : ',True if logits_clsf else False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whs1NrKnaUBX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Kj16uBlaVaL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}